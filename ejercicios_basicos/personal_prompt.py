"""
ğŸ“˜ Ejercicio BÃ¡sico 2 - Chatbot con prompt personalizado

ğŸ¯ Objetivo:
Crear un asistente controlado con un prompt estructurado, capaz de responder segÃºn un estilo o rol definido (por ejemplo, como profesor, mÃ©dico o soporte tÃ©cnico).

ğŸ› ï¸ Herramientas utilizadas:
- `PromptTemplate`: Para definir cÃ³mo se estructura la entrada.
- `LLMChain`: Para unir el modelo con el prompt.
- `ChatOpenAI`: Modelo de lenguaje para generar las respuestas.

ğŸ’¡ Ideas de extensiÃ³n:
- Agregar mÃºltiples roles (mÃ©dico, abogado, etc.)
- Cambiar el formato de salida (respuestas en lista, JSON, etc.)
- Incluir instrucciones de comportamiento en el prompt

ğŸ“¦ Requisitos:
- langchain
- openai
- python-dotenv
"""

import os
import sys
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

load_dotenv()

llm = ChatOpenAI(
    model="gpt-4o-mini",
    temperature=0.5
)

prompt_template = ChatPromptTemplate([
    ("system", """Eres un asistente experto en explicar conceptos tÃ©cnicos de manera sencilla.
Tu tarea es responder preguntas como si le hablaras a un estudiante de secundaria."""),
    ("user", "{pregunta}")
])

question = input("Ingresa una pregunta: ")
messages = prompt_template.invoke({"pregunta": question})

response = llm.invoke(messages)
print(response.content)
















