"""
ğŸ“š Ejercicio Intermedio 1 - Chat con documentos locales (RAG simple)

ğŸ¯ Objetivo:
Crear un chatbot que responda preguntas sobre documentos locales utilizando el patrÃ³n RAG (Retrieval-Augmented Generation), combinando recuperaciÃ³n semÃ¡ntica con generaciÃ³n LLM.

ğŸ› ï¸ Herramientas utilizadas:
- `TextLoader` o `PyPDFLoader`: para cargar archivos locales.
- `RecursiveCharacterTextSplitter`: para dividir texto en fragmentos.
- `OpenAIEmbeddings`: para convertir fragmentos en vectores.
- `FAISS`: para hacer bÃºsquedas semÃ¡nticas eficientes.
- `ChatOpenAI`: para generar respuestas basadas en los fragmentos encontrados.
- `RetrievalQA`: para conectar todo el pipeline.

ğŸ’¡ Ideas de extensiÃ³n:
- Usar mÃºltiples archivos o carpetas.
- Guardar y reutilizar el Ã­ndice vectorial FAISS.
- Mostrar los fragmentos usados en la respuesta.

ğŸ“¦ Requisitos:
- langchain
- langchain-openai
- faiss-cpu
- pypdf
- python-dotenv
"""

# import os
# from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

def load_documents(file_path):
    file_path = "./a-practical-guide-to-building-agents.pdf"
    loader = PyPDFLoader(file_path)
    documents = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        add_start_index=True,
    )

    all_splits = text_splitter.split_documents(documents)
    create_vector_store(all_splits)


def create_vector_store(documents):
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    