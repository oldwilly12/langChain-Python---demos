"""
ğŸ“š Ejercicio Intermedio 2 - Chat con mÃºltiples documentos

ğŸ¯ Objetivo:
Construir un asistente que pueda responder preguntas basadas en varios archivos (PDF o TXT) almacenados en una carpeta, integrando todo el conocimiento en una sola base vectorial.

ğŸ§  Â¿QuÃ© aprenderÃ¡s en este ejercicio?
- CÃ³mo cargar mÃºltiples documentos desde una carpeta usando `DirectoryLoader`
- CÃ³mo dividir su contenido con `RecursiveCharacterTextSplitter`
- CÃ³mo generar embeddings con `OpenAIEmbeddings`
- CÃ³mo indexar todos los documentos juntos en una sola colecciÃ³n en Qdrant
- CÃ³mo realizar bÃºsquedas semÃ¡nticas que abarquen varios textos

ğŸ› ï¸ Herramientas utilizadas:
- `DirectoryLoader`: carga masiva de documentos
- `RecursiveCharacterTextSplitter`: fragmentaciÃ³n de textos
- `OpenAIEmbeddings`: vectorizaciÃ³n de fragmentos
- `QdrantVectorStore`: almacenamiento semÃ¡ntico escalable
- `QdrantClient`: creaciÃ³n y control de la colecciÃ³n

ğŸ’¡ Â¿Por quÃ© es importante este ejercicio?
Este ejercicio te prepara para:
- Construir asistentes que consulten **bases documentales reales** (manuales, reportes, polÃ­ticas)
- Escalar de uno a muchos archivos sin cambiar tu lÃ³gica
- Preparar bases de conocimiento mÃ¡s completas para agentes o apps empresariales

ğŸš€ Este paso es clave antes de construir un agente inteligente que tome decisiones (Ejercicio Avanzado 1) o un asistente profesional como los que usarÃ­as en medicina, soporte o ventas.
"""

import os
from dotenv import load_dotenv
from langchain_community.document_loaders import DirectoryLoader
from langchain_community.document_loaders import PyPDFLoader
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()

docs_path = os.path.join(os.path.dirname(__file__), "..", "documents")

def load_documents():
    loader = DirectoryLoader(
        path=docs_path,
        glob="**/*.pdf", # Carga todos los archivos en subdirectorios
        show_progress=True
    )
    docs = loader.load()
    len(docs)
    print(docs[0].page_content[:100])


load_documents()